Random Forest:
  criterion: ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']
  n_estimators: [8,16,32,64,128,256]

Decision Tree:
  criterion: ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']
  splitter: ['best','random']
  max_depth: [ 1,  4,  7, 10, 13, 16, 19, 22, 25, 28]
  max_features: [0.25,0.5,0.75,1.0]
  min_samples_split: [ 2,  5,  8, 11, 14, 17]

Gradient Boosting:
  loss: ['squared_error', 'huber', 'absolute_error', 'quantile']
  learning_rate: [.1,.01,.05,.001]
 # subsample: [0.6,0.7,0.75,0.8,0.85,0.9]
  criterion: ['squared_error', 'friedman_mse']
  n_estimators: [8,16,32,64,128,256]

AdaBoost Regressor:
  learning_rate: [.1,.01,0.5,.001]
  loss: ['linear','square','exponential']
  n_estimators: [8,16,32,64,128,256]